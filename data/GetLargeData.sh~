#!/bin/bash
#full pfam.unipront is downloaded!
#allow 2TB of free disk space
#afterwards, most of it can be freed as we select only as small subset of the families
mkdir large
cd large
get_fasta_data() {
    file=$1
    wget http://ftp.ebi.ac.uk/pub/databases/Pfam/releases/Pfam35.0/$file.gz
    gunzip $file.gz
    mkdir ${file}_data
    python3 ../src/SplitStockholm.py $file ${file}_data
    cd ../src
    ./Stockholm2Fasta.sh "../large/${file}_data/*.stockholm"
    cd ../large
    #rm ${file}_data/*.stockholm
}
get_fasta_data "Pfam-A.full"
get_fasta_data "Pfam-A.full.uniprot"
get_fasta_data "Pfam-A.seed"
mkdir train
mkdir refs
large_ids=("PF00096.29" "PF00400.35" "PF00005.30" "PF00069.28" "PF12796.10")
for id in ${large_ids[@]};
do
    cp Pfam-A.seed_data/${id}.fasta refs/${id}.ref
    chmod -w  refs/${id}.ref
    touch train/${id}.fasta
    python3 ../src/RemoveGapsAndMerge.py train/${id}.fasta refs/${id}.ref
    python3 ../src/RemoveGapsAndMerge.py train/${id}.fasta Pfam-A.full.uniprot_data/${id}.fasta
    chmod -w train/${id}.fasta
done







